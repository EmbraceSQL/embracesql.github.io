"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5993],{9327:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>u,frontMatter:()=>l,metadata:()=>c,toc:()=>h});var i=t(5893),a=t(1151),s=t(9286);const r='import { Database } from "../../src/marshalling";\n\ndescribe("The database can", () => {\n  let db: Database;\n  beforeAll(async () => {\n    db = await Database.connect(\n      "postgres://postgres:postgres@localhost:5432/marshalling",\n    );\n  });\n  afterAll(async () => {\n    await db.disconnect();\n  });\n  beforeEach(() => {\n    // no middleware, we\'ll be adding middleware\n    db.clear();\n  });\n  it("recover from a killed connection", async () => {\n    db.use(async (context, next) => {\n      // simulate a really bad disconnect, some DBA type smote you \ud83d\udde1\ufe0f\n      // we won\'t do this on any subsequent retries\n      if (context.retry === 0) {\n        await context.sql`SELECT pg_terminate_backend(pid) FROM (SELECT pg_backend_pid() pid)`;\n      }\n      return next();\n    });\n    const ret = await db.Api.Procedures.Echo.call(\n      {\n        message: "Hello",\n      },\n      {\n        retries: 1,\n      },\n    );\n    expect(ret).toBe("Hello");\n  });\n});\n',l={},o="Reliability",c={id:"reliability",title:"Reliability",description:"Stuff breaks \ud83d\udc94. EmbraceSQL tries to make this less painful.",source:"@site/docs/reliability.mdx",sourceDirName:".",slug:"/reliability",permalink:"/docs/reliability",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Problems",permalink:"/docs/problems"},next:{title:"Security",permalink:"/docs/security"}},d={},h=[{value:"End to End Retry",id:"end-to-end-retry",level:2},{value:"Pooling",id:"pooling",level:2},{value:"Testing",id:"testing",level:2}];function p(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",li:"li",p:"p",ul:"ul",...(0,a.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"reliability",children:"Reliability"}),"\n",(0,i.jsx)(n.p,{children:"Stuff breaks \ud83d\udc94. EmbraceSQL tries to make this less painful."}),"\n",(0,i.jsx)(n.h2,{id:"end-to-end-retry",children:"End to End Retry"}),"\n",(0,i.jsx)(n.p,{children:"Interrupted networks connections happen unpredictably. Particularly in containerized\nsetups, servers are starting and stopping. Load balancers are taking services\nin and out."}),"\n",(0,i.jsx)(n.p,{children:"These interruptions can happen between client/web, web/api, and api/database. Folks\nknow that retry logic is an effective technique to mask transient errors -- but\ncoding up all those retries, and coding them both client and server is a huge chore \u26cf\ufe0f."}),"\n",(0,i.jsxs)(n.p,{children:["EmbraceSQL provides a ",(0,i.jsx)(n.code,{children:"retries"})," option, which can be set that will automatically\nretry calls - both client and server - with exponential backoff."]}),"\n",(0,i.jsxs)(n.p,{children:["You can set this overall on ",(0,i.jsx)(n.a,{href:"./React/Cookbook/client_retry",children:"EmbraceSQLClient"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"pooling",children:"Pooling"}),"\n",(0,i.jsx)(n.p,{children:"EmbraceSQL uses a connection pool, but by default only leaves connections\nin the pool for 30 seconds. This resists 'torn' or 'dead' connections clogging\nup the pool that can result from:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"network transients"}),"\n",(0,i.jsx)(n.li,{children:"database restarts, particularly in a serveless setup"}),"\n",(0,i.jsx)(n.li,{children:"database providers (or DBAs \ud83d\ude0f) that kill connections"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"testing",children:"Testing"}),"\n",(0,i.jsx)(n.p,{children:"Here is an example test from the source -- you can see EmbraceSQL can live through\neven a pathological query that occasionally kills itself."}),"\n",(0,i.jsx)(s.Z,{language:"typescript",children:r})]})}function u(e={}){const{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}}}]);